# 相机位姿估计

1. #### 相机位姿估计常见方法https://blog.csdn.net/q7w8e9r4/article/details/132923533

2. ### Intel Realsense D435i + Apriltag_ros 实现对相机姿态的估计

   https://blog.csdn.net/nenchoumi3119/article/details/127115369?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522170919195416800225580326%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=170919195416800225580326&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-10-127115369-null-null.142

3. #### 深度的获取

- 深度相机：取每个像素的深度信息。对于每个像素 (u, v)，深度相机提供其深度值 ZcZ_cZc

- 立体视觉系统：两台相机拍摄同一场景。通过立体匹配算法计算视差图，然后根据视差值计算深度 ZcZ_cZ

  - **拍摄图像**：使用左右相机同时拍摄同一场景的图像。

  - **立体匹配**：通过立体匹配算法计算左右图像中的每个像素的视差 d。

  - **计算深度**：根据视差计算深度 ZcZ_cZc

    ```
    Zc=f⋅B/d
    ```

    f 是相机的焦距，B是相机基线距离（两个相机之间的距离），d视差。

- 激光雷达:提供高精度的深度信息。通过激光测距原理，激光雷达可以直接测量到物体的距离 ZcZ_cZc

- 单目视觉方法估算深度:依赖于特定的假设或额外的信息,已知的物体大小、场景结构或运动信息。比如通过使用结构化光、运动立体等方法来估算深度

  - 基于大小

  $$
  Z 
  c
  ​
   = 
   
   f⋅h 
  real
  ​
   /
  ​
   
  h 
  pixels
  ​
  $$

  - 基于透视投影模型:相机透视投影模型，通过相机的内外参数，将图像坐标转换为世界坐标，然后估算深度(视觉Slam动态更新相机外参)

    - 点投影

    $$
    [u \
    v \
    1]T
    ​
      
    ​
     =K[R∣T] 
    ​
      
    [X 
    w
    ​
     
    Y 
    w
    ​
     
    Z 
    w
    ​
     
    1
    ​
      
    ​]T
    $$

    - 逆投影：用相机内参矩阵 KKK 和外参矩阵 [R∣T][R | T][R∣T] 的逆矩阵，将图像坐标转换为相机坐标系或世界坐标系中的坐标，从而估算深度。

      外参：

      - 相机位置角度决定了外参

      - 实时更新相机外参(移动相机或动态场景)：外部传感器或视觉SLAM（Simultaneous Localization and Mapping）系统进行实时估计和更新

        基于多帧图像和运动估计的方法（如SfM)

        - 视觉SLAM系统通过分析相机拍摄的连续图像，实时计算相机的位姿变化，从而更新外参

        - 视觉SLAM的核心是动态更新相机的外参，即相机的姿态（位置和方向）

          - 1. 特征提取与匹配

            - **特征提取**：在每一帧图像中提取特征点，如ORB（Oriented FAST and Rotated BRIEF）、SIFT（Scale-Invariant Feature Transform）或SURF（Speeded Up Robust Features）。
            - **特征匹配**：在连续帧之间或在当前帧与关键帧之间进行特征匹配。匹配方法可以是暴力匹配、FLANN（Fast Library for Approximate Nearest Neighbors）等。

          - 2. 运动估计

            通过匹配的特征点，计算相机的运动（即相机的位姿变化）。常用的方法包括：

            - **PnP（Perspective-n-Point）**：解决3D-2D点对的位姿估计问题。
            - **五点法或八点法**：用于估计基础矩阵或本质矩阵，从而推导相机的相对运动。
            - **直接法**：通过最小化图像间的光度误差直接估计运动。

          - 3. 位姿优化

            使用非线性优化方法（如Bundle Adjustment）优化相机位姿和3D点的位置。优化的目标是最小化重投影误差： 重投影误差=∑i∑j∥uij−π(RjXi+tj)∥2\text{重投影误差} = \sum_i \sum_j \left\| \mathbf{u}_{ij} - \pi(\mathbf{R}_j \mathbf{X}_i + \mathbf{t}_j) \right\|^2重投影误差=∑i∑j∥uij−π(RjXi+tj)∥2 其中，uij\mathbf{u}_{ij}uij 是第 jjj 个相机中第 iii 个3D点的观测，π\piπ 是投影函数，Rj\mathbf{R}_jRj 和 tj\mathbf{t}_jtj 是第 jjj 个相机的旋转和平移矩阵，Xi\mathbf{X}_iXi 是第 iii 个3D点的世界坐标。

          - 4. 地图构建与更新

            在构建和更新地图的过程中，需要确定关键帧（关键位置）并保持一个稀疏的特征点云。SLAM系统会不断添加新的关键帧，并在地图中添加新的特征点。

          - 5. 回环检测

            为了减少漂移误差，视觉SLAM系统通常包括回环检测模块。当检测到当前帧与以前的关键帧存在回环时，使用回环检测结果进行全局优化（如Pose Graph Optimization）。

  - 基于深度学习：

    深度学习模型（如单目深度估计网络）直接从单张图像中估算深度。这种方法需要大量的训练数据，并且模型需要事先训练好

    - **准备数据**：收集并标注包含深度信息的数据集。

      **训练模型**：使用卷积神经网络（如Monodepth、DPT等）进行训练。

      **深度预测**：将输入图像传递给训练好的模型，输出每个像素的深度。

    

4. #### 图像校正

- **畸变校正**：使用OpenCV中的`undistort`函数对图像进行校正，输入相机内参和畸变系数，输出校正后的图像。
- **图像处理**：进行边缘检测、特征提取等操作，以便后续的深度估计。

```
import cv2
import numpy as np

# 加载标定参数
K = np.array([[fx, 0, cx],
              [0, fy, cy],
              [0, 0, 1]])
D = np.array([k1, k2, p1, p2, k3])

# 读取图像
image = cv2.imread('input_image.jpg')

# 获取图像尺寸
h, w = image.shape[:2]

# 计算校正后的相机矩阵
new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(K, D, (w, h), 1, (w, h))

# 校正图像
undistorted_image = cv2.undistort(image, K, D, None, new_camera_matrix)

# 裁剪图像（可选）:根据roi（感兴趣区域）裁剪校正后的图像以去除黑边。
x, y, w, h = roi
undistorted_image = undistorted_image[y:y+h, x:x+w]

# 保存校正后的图像
cv2.imwrite('output_image.jpg', undistorted_image)
```

5. #### 世界坐标系确定

- 固定世界坐标系（选定一个固定点）

```

```

- 标定板坐标系（棋盘格作原点）
- 待定物体坐标系（机器人基座中心）
